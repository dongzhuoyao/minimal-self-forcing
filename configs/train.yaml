# Self-Forcing Training Configuration
# Usage: python train.py
# Override: python train.py training.num_steps=2000 checkpoint=logs/pretrain/checkpoint_final.pt

defaults:
  - config  # Inherit from base config.yaml

# Hydra settings
hydra:
  # Use default Hydra output directory (outputs/)
  # To customize: uncomment and set dir: ${paths.output_dir}
  # run:
  #   dir: ${paths.output_dir}
  job:
    chdir: false

# Training Hyperparameters (Self-Forcing specific)
training:
  pretrained_checkpoint: ./outputs/2026-01-17/10-46-03/checkpoint_step_039000.pt    # Pretrained checkpoint to load
  num_steps: 100000              # Number of training steps
  batch_size: 4               # Batch size
  lr: 1e-3                   # Learning rate (1e-3)
  weight_decay: 0.01           # Weight decay for optimizer
  gradient_clip_norm: 1.0      # Gradient clipping max norm

  # Self-Forcing video generation
  num_frames: 21               # Number of frames for training (7 blocks Ã— 3 frames)
  num_frames_per_block: 3      # Frames per block
  denoising_steps: [1000, 750, 500, 250]  # Denoising timesteps
  context_noise: 0             # Noise level for cache update
  use_dmd_loss: true           # Use DMD loss (true) or simplified temporal loss (false)
  
  # Flow Matching settings (model uses Flow Matching internally)
  # Note: The model predicts flow, but current DMD implementation uses x0 predictions
  # Original impl uses denoising_loss_type: flow for flow-based DMD loss
  denoising_loss_type: "flow"  # Denoising loss type: "flow" (Flow Matching), "x0", "noise", or "v"

  # DMD-specific configs (optional, with defaults)
  num_train_timestep: 1000      # Number of training timesteps
  guidance_scale: 1.0            # Guidance scale for generation
  timestep_shift: 1.0            # Timestep shift factor
  ts_schedule: false             # Use timestep schedule
  ts_schedule_max: false         # Maximum timestep schedule
  min_score_timestep: 0          # Minimum score timestep
  min_num_frames: 21             # Minimum number of frames
  max_num_frames: null           # Maximum number of frames (null = use training_num_frames)

  # Training control
  save_interval: 1000         # Save checkpoint every N steps
  log_interval: 10             # Log metrics every N steps
  viz_interval: 100            # Generate sample videos every N steps

  # Dataset
  num_samples: 20              # Number of training samples in dataset
  video_height: 64             # Video height
  video_width: 64              # Video width
  video_frames: 9              # Number of frames per video in dataset



# Checkpoint to load (null for training from scratch)
# For fine-tuning after pretraining:
#   python train.py checkpoint=logs/pretrain/checkpoint_final.pt
checkpoint: null

# Wandb settings (separate project for pretraining)
wandb:
  enabled: true
  project: "minimal-self-forcing"
  entity: dpose-team
  name: null
