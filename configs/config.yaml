# Self-Forcing Tutorial Configuration
# This config contains all hyperparameters for training and generation

# Model Architecture
model:
  in_dim: 3                    # Input channels (RGB)
  out_dim: 3                  # Output channels
  dim: 256                    # Hidden dimension
  ffn_dim: 1024              # FFN dimension
  num_heads: 4                # Attention heads
  num_layers: 4               # Transformer layers
  patch_size: [1, 2, 2]       # Patch size for embedding
  text_dim: 128               # Text embedding dimension
  freq_dim: 256               # Time embedding dimension
  num_frame_per_block: 3      # Frames per block for causal mask

# Text Encoder
text_encoder:
  text_dim: 128               # Text embedding dimension
  text_len: 77                # Maximum text length
  vocab_size: 256             # Vocabulary size (character-level)

# Training Hyperparameters
training:
  num_steps: 10000            # Number of training steps
  batch_size: 64              # Batch size
  lr: 0.0001                  # Learning rate (1e-4)
  weight_decay: 0.01          # Weight decay for optimizer
  gradient_clip_norm: 1.0     # Gradient clipping max norm
  
  # Training video generation
  num_frames: 21              # Number of frames for training (7 blocks Ã— 3 frames)
  num_frames_per_block: 3     # Frames per block
  denoising_steps: [1000, 750, 500, 250]  # Denoising timesteps
  context_noise: 0            # Noise level for cache update
  
  # Training control
  save_interval: 10           # Save checkpoint every N steps
  log_interval: 5             # Log metrics every N steps
  viz_interval: 100           # Generate sample videos every N steps
  
  # Dataset
  num_samples: 20             # Number of training samples in toy dataset
  video_height: 64            # Video height for training
  video_width: 64             # Video width for training
  video_frames: 9             # Number of frames per video in dataset

# Generation/Inference Hyperparameters
generation:
  num_frames: 9               # Number of frames to generate
  num_frames_per_block: 3     # Frames per block (must divide num_frames)
  denoising_steps: [1000, 750, 500, 250]  # Denoising timesteps
  output_dir: "outputs/generated"  # Output directory for generated videos
  
  # Sample generation during training
  num_viz_samples: 4          # Number of sample videos to generate during training
  viz_num_frames: 9           # Number of frames for visualization samples

# Paths and Directories
paths:
  log_dir: "logs/training"    # Directory for logs and checkpoints
  checkpoint: "logs/training/checkpoint_final.pt"  # Default checkpoint path
  output_dir: "outputs/generated"  # Output directory

# Device and Randomness
device: "cuda"                # Device to use (cuda/cpu, auto-detected if not available)
seed: 42                      # Random seed for reproducibility

# Visualization Prompts (for sample generation during training)
viz_prompts:
  - "A red circle moving horizontally"
  - "A blue square rotating clockwise"
  - "A yellow ball bouncing"
  - "Color gradient transitioning from red to blue"
